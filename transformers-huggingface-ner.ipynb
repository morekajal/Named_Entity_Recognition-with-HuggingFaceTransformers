{"cells":[{"cell_type":"markdown","metadata":{},"source":["- We will first use the Pre-trained models from Hugging Face to reduce the computational cost\n","- https://huggingface.co/\n","- "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:24:47.473606Z","iopub.status.busy":"2024-03-04T14:24:47.472858Z","iopub.status.idle":"2024-03-04T14:25:05.684694Z","shell.execute_reply":"2024-03-04T14:25:05.683480Z","shell.execute_reply.started":"2024-03-04T14:24:47.473574Z"},"trusted":true},"outputs":[],"source":["!pip install transformers datasets tokenizer seqeval -q"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:05.687073Z","iopub.status.busy":"2024-03-04T14:25:05.686711Z","iopub.status.idle":"2024-03-04T14:25:25.672214Z","shell.execute_reply":"2024-03-04T14:25:25.671319Z","shell.execute_reply.started":"2024-03-04T14:25:05.687044Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-04 14:25:16.623251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-04 14:25:16.623354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-04 14:25:16.789333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import datasets\n","import numpy as np\n","from transformers import BertTokenizerFast\n","from transformers import DataCollatorForTokenClassification\n","from transformers import AutoModelForTokenClassification"]},{"cell_type":"markdown","metadata":{},"source":["- Hugging Face Datasets: https://huggingface.co/docs/datasets/quickstart\n","- Hugging face provides Audio, Vision, NLP datasets\n","- "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:25.674386Z","iopub.status.busy":"2024-03-04T14:25:25.673574Z","iopub.status.idle":"2024-03-04T14:25:39.101831Z","shell.execute_reply":"2024-03-04T14:25:39.100728Z","shell.execute_reply.started":"2024-03-04T14:25:25.674347Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of datasets available on Hugging Face: 115130\n"]}],"source":["# Lets check the list of datasets available in Hugging Face\n","\n","from datasets import list_datasets\n","datasets_list = list_datasets()\n","\n","num_datasets = len(datasets_list)\n","print(\"Number of datasets available on Hugging Face:\", num_datasets)"]},{"cell_type":"markdown","metadata":{},"source":["- We are going to do a NER task with the \"conll2003\" dataset, having 4 types of entities : persons, locations, organization and miscellaneous\n","- https://huggingface.co/datasets/conll2003"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:39.104179Z","iopub.status.busy":"2024-03-04T14:25:39.103882Z","iopub.status.idle":"2024-03-04T14:25:47.287507Z","shell.execute_reply":"2024-03-04T14:25:47.286589Z","shell.execute_reply.started":"2024-03-04T14:25:39.104153Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e833ea7a9da948c3bfd4fb391fd8187d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0016339c9fb04382bc78a568363b354d","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"454f767439b5446789fe7ad6968f3322","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/3251 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/3454 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd7167a16c1a484fbf5c91e9fc1fa964","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["coll_dataset = datasets.load_dataset(\"conll2003\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.288986Z","iopub.status.busy":"2024-03-04T14:25:47.288675Z","iopub.status.idle":"2024-03-04T14:25:47.295564Z","shell.execute_reply":"2024-03-04T14:25:47.294596Z","shell.execute_reply.started":"2024-03-04T14:25:47.288955Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 14042\n","    })\n","    validation: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 3251\n","    })\n","    test: Dataset({\n","        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","        num_rows: 3454\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["coll_dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.297197Z","iopub.status.busy":"2024-03-04T14:25:47.296878Z","iopub.status.idle":"2024-03-04T14:25:47.308261Z","shell.execute_reply":"2024-03-04T14:25:47.307359Z","shell.execute_reply.started":"2024-03-04T14:25:47.297172Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","    num_rows: 14042\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["coll_dataset[\"train\"]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.310248Z","iopub.status.busy":"2024-03-04T14:25:47.309627Z","iopub.status.idle":"2024-03-04T14:25:47.321011Z","shell.execute_reply":"2024-03-04T14:25:47.320137Z","shell.execute_reply.started":"2024-03-04T14:25:47.310196Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': '0',\n"," 'tokens': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.'],\n"," 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n"," 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n"," 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["coll_dataset[\"train\"][0]"]},{"cell_type":"markdown","metadata":{},"source":["POS tagging : Part-of-speech (POS) tagging is a process in natural language processing (NLP) where each word in a sentence is tagged with its corresponding part of speech, such as noun, verb, adjective, etc. The main goal of POS tagging is to assign the correct grammatical category to each word in a given text automatically.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["NER : NER stands for Named Entity Recognition. It is a subtask of natural language processing (NLP) that involves identifying and classifying named entities within a text into predefined categories such as names of persons, organizations, locations, dates, numerical expressions, and more."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.322441Z","iopub.status.busy":"2024-03-04T14:25:47.322083Z","iopub.status.idle":"2024-03-04T14:25:47.332628Z","shell.execute_reply":"2024-03-04T14:25:47.331803Z","shell.execute_reply.started":"2024-03-04T14:25:47.322407Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# extract ner tags from features\n","coll_dataset[\"train\"].features['ner_tags']"]},{"cell_type":"markdown","metadata":{},"source":["Their are 9 classes availble in ner_tags"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.333851Z","iopub.status.busy":"2024-03-04T14:25:47.333570Z","iopub.status.idle":"2024-03-04T14:25:47.343514Z","shell.execute_reply":"2024-03-04T14:25:47.342626Z","shell.execute_reply.started":"2024-03-04T14:25:47.333828Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#checkout the description of the data\n","coll_dataset['train'].description"]},{"cell_type":"markdown","metadata":{},"source":["#### The Pipeline (collection of components) : will use HuggingFacePipeline to collect all this components\n","- Data Ingestion\n","- Data Preprocessing\n","- Model Training\n","- Model Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["In the model training part : will use Bert-uncased model -> will lowercase the text -> Then will FineTune the model -> and save the model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:47.347603Z","iopub.status.busy":"2024-03-04T14:25:47.347247Z","iopub.status.idle":"2024-03-04T14:25:48.479855Z","shell.execute_reply":"2024-03-04T14:25:48.478904Z","shell.execute_reply.started":"2024-03-04T14:25:47.347578Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa892ba9bc1343caba734cb843b8d95a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f079a8e3e184070a4ee8f4d9e97654a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d80538ab3fdf461292ae21c22c563009","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9849f92afc8748b8a5c12fb520b4d464","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Import tokenizer\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.481325Z","iopub.status.busy":"2024-03-04T14:25:48.481035Z","iopub.status.idle":"2024-03-04T14:25:48.486120Z","shell.execute_reply":"2024-03-04T14:25:48.485040Z","shell.execute_reply.started":"2024-03-04T14:25:48.481299Z"},"trusted":true},"outputs":[],"source":["# will tokenize the train data\n","\n","# lets first try and see the tokenizer on a random example\n","example_text = coll_dataset['train'][405]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.487564Z","iopub.status.busy":"2024-03-04T14:25:48.487291Z","iopub.status.idle":"2024-03-04T14:25:48.500977Z","shell.execute_reply":"2024-03-04T14:25:48.499973Z","shell.execute_reply.started":"2024-03-04T14:25:48.487540Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': '405',\n"," 'tokens': ['Kenny',\n","  'Dalglish',\n","  'spoke',\n","  'on',\n","  'Thursday',\n","  'of',\n","  'his',\n","  'sadness',\n","  'at',\n","  'leaving',\n","  'Blackburn',\n","  ',',\n","  'the',\n","  'club',\n","  'he',\n","  'led',\n","  'to',\n","  'the',\n","  'English',\n","  'premier',\n","  'league',\n","  'title',\n","  'in',\n","  '1994-95',\n","  '.'],\n"," 'pos_tags': [22,\n","  22,\n","  38,\n","  15,\n","  22,\n","  15,\n","  29,\n","  21,\n","  15,\n","  39,\n","  22,\n","  6,\n","  12,\n","  21,\n","  28,\n","  38,\n","  35,\n","  12,\n","  16,\n","  16,\n","  21,\n","  21,\n","  15,\n","  11,\n","  7],\n"," 'chunk_tags': [11,\n","  12,\n","  21,\n","  13,\n","  11,\n","  13,\n","  11,\n","  12,\n","  13,\n","  21,\n","  11,\n","  0,\n","  11,\n","  12,\n","  11,\n","  21,\n","  13,\n","  11,\n","  12,\n","  12,\n","  12,\n","  12,\n","  13,\n","  11,\n","  0],\n"," 'ner_tags': [1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  3,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  7,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["example_text"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.502363Z","iopub.status.busy":"2024-03-04T14:25:48.502101Z","iopub.status.idle":"2024-03-04T14:25:48.511243Z","shell.execute_reply":"2024-03-04T14:25:48.510393Z","shell.execute_reply.started":"2024-03-04T14:25:48.502342Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Kenny',\n"," 'Dalglish',\n"," 'spoke',\n"," 'on',\n"," 'Thursday',\n"," 'of',\n"," 'his',\n"," 'sadness',\n"," 'at',\n"," 'leaving',\n"," 'Blackburn',\n"," ',',\n"," 'the',\n"," 'club',\n"," 'he',\n"," 'led',\n"," 'to',\n"," 'the',\n"," 'English',\n"," 'premier',\n"," 'league',\n"," 'title',\n"," 'in',\n"," '1994-95',\n"," '.']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["example_text['tokens']"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.512730Z","iopub.status.busy":"2024-03-04T14:25:48.512339Z","iopub.status.idle":"2024-03-04T14:25:48.529890Z","shell.execute_reply":"2024-03-04T14:25:48.529159Z","shell.execute_reply.started":"2024-03-04T14:25:48.512700Z"},"trusted":true},"outputs":[],"source":["tokenized_input = tokenizer(example_text['tokens'], is_split_into_words=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.531077Z","iopub.status.busy":"2024-03-04T14:25:48.530846Z","iopub.status.idle":"2024-03-04T14:25:48.536312Z","shell.execute_reply":"2024-03-04T14:25:48.535458Z","shell.execute_reply.started":"2024-03-04T14:25:48.531057Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [101, 8888, 17488, 25394, 4095, 3764, 2006, 9432, 1997, 2010, 12039, 2012, 2975, 13934, 1010, 1996, 2252, 2002, 2419, 2000, 1996, 2394, 4239, 2223, 2516, 1999, 2807, 1011, 5345, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_input"]},{"cell_type":"markdown","metadata":{},"source":["Convert Id's into tokens"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.537698Z","iopub.status.busy":"2024-03-04T14:25:48.537374Z","iopub.status.idle":"2024-03-04T14:25:48.549097Z","shell.execute_reply":"2024-03-04T14:25:48.548252Z","shell.execute_reply.started":"2024-03-04T14:25:48.537667Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[101,\n"," 8888,\n"," 17488,\n"," 25394,\n"," 4095,\n"," 3764,\n"," 2006,\n"," 9432,\n"," 1997,\n"," 2010,\n"," 12039,\n"," 2012,\n"," 2975,\n"," 13934,\n"," 1010,\n"," 1996,\n"," 2252,\n"," 2002,\n"," 2419,\n"," 2000,\n"," 1996,\n"," 2394,\n"," 4239,\n"," 2223,\n"," 2516,\n"," 1999,\n"," 2807,\n"," 1011,\n"," 5345,\n"," 1012,\n"," 102]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_input['input_ids']"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.550616Z","iopub.status.busy":"2024-03-04T14:25:48.550181Z","iopub.status.idle":"2024-03-04T14:25:48.560007Z","shell.execute_reply":"2024-03-04T14:25:48.559114Z","shell.execute_reply.started":"2024-03-04T14:25:48.550586Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," 'kenny',\n"," 'dal',\n"," '##gli',\n"," '##sh',\n"," 'spoke',\n"," 'on',\n"," 'thursday',\n"," 'of',\n"," 'his',\n"," 'sadness',\n"," 'at',\n"," 'leaving',\n"," 'blackburn',\n"," ',',\n"," 'the',\n"," 'club',\n"," 'he',\n"," 'led',\n"," 'to',\n"," 'the',\n"," 'english',\n"," 'premier',\n"," 'league',\n"," 'title',\n"," 'in',\n"," '1994',\n"," '-',\n"," '95',\n"," '.',\n"," '[SEP]']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n","tokens"]},{"cell_type":"markdown","metadata":{},"source":["- The tokens \"[CLS]\" and \"[SEP]\" are special tokens used in the pre-training and fine-tuning of Transformer-based models in natural language processing (NLP)\n","\n","1. \"[CLS]\": This token stands for \"classification.\" It is prepended to the input sequence in BERT-based models and serves as a special token to represent the beginning of the sequence. During fine-tuning for specific downstream tasks such as text classification or sentence pair classification, the output representation corresponding to the \"[CLS]\" token is used as input to a task-specific classifier.\n","\n","2. \"[SEP]\": This token stands for \"separator.\" It is used to separate two sentences or sequences in input. It is used both during pre-training, where BERT is trained on tasks like next sentence prediction, and during fine-tuning, where BERT might be used for tasks like question answering where it is important to separate question and context or for tasks like sentence pair classification."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.561709Z","iopub.status.busy":"2024-03-04T14:25:48.561154Z","iopub.status.idle":"2024-03-04T14:25:48.574933Z","shell.execute_reply":"2024-03-04T14:25:48.572995Z","shell.execute_reply.started":"2024-03-04T14:25:48.561679Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n","    num_rows: 14042\n","})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["coll_dataset['train']"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.576857Z","iopub.status.busy":"2024-03-04T14:25:48.576576Z","iopub.status.idle":"2024-03-04T14:25:48.584212Z","shell.execute_reply":"2024-03-04T14:25:48.583270Z","shell.execute_reply.started":"2024-03-04T14:25:48.576834Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[None, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, None]\n"]}],"source":["# get the token_ids for example_text\n","word_ids = tokenized_input.word_ids()\n","\n","print(word_ids)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.585627Z","iopub.status.busy":"2024-03-04T14:25:48.585331Z","iopub.status.idle":"2024-03-04T14:25:48.597666Z","shell.execute_reply":"2024-03-04T14:25:48.596885Z","shell.execute_reply.started":"2024-03-04T14:25:48.585605Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["example_text[\"ner_tags\"]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.599279Z","iopub.status.busy":"2024-03-04T14:25:48.598989Z","iopub.status.idle":"2024-03-04T14:25:48.608114Z","shell.execute_reply":"2024-03-04T14:25:48.607335Z","shell.execute_reply.started":"2024-03-04T14:25:48.599239Z"},"trusted":true},"outputs":[],"source":["def tokenize_and_align_labels(examples, label_all_tokens=True):\n","\n","    #tokeinze ids\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","    labels = []\n","\n","\n","    for i, label in enumerate(examples[\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        # word_ids() => Return a list mapping the tokens\n","        # to their actual word in the initial sentence.\n","        # It Returns a list indicating the word corresponding to each token.\n","\n","        previous_word_idx = None\n","        label_ids = []\n","        # Special tokens like `` and `<\\s>` are originally mapped to None\n","        # We need to set the label to -100 so they are automatically ignored in the loss function.\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                # set –100 as the label for these special tokens\n","                label_ids.append(-100)\n","\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            elif word_idx != previous_word_idx:\n","                # if current word_idx is != prev then its the most regular case\n","                # and add the corresponding token\n","                label_ids.append(label[word_idx])\n","            else:\n","                # to take care of sub-words which have the same word_idx\n","                # set -100 as well for them, but only if label_all_tokens == False\n","                label_ids.append(label[word_idx] if label_all_tokens else -100)\n","                # mask the subword representations after the first subword\n","\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.609229Z","iopub.status.busy":"2024-03-04T14:25:48.608985Z","iopub.status.idle":"2024-03-04T14:25:48.627220Z","shell.execute_reply":"2024-03-04T14:25:48.626346Z","shell.execute_reply.started":"2024-03-04T14:25:48.609207Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': ['4'],\n"," 'tokens': [['Germany',\n","   \"'s\",\n","   'representative',\n","   'to',\n","   'the',\n","   'European',\n","   'Union',\n","   \"'s\",\n","   'veterinary',\n","   'committee',\n","   'Werner',\n","   'Zwingmann',\n","   'said',\n","   'on',\n","   'Wednesday',\n","   'consumers',\n","   'should',\n","   'buy',\n","   'sheepmeat',\n","   'from',\n","   'countries',\n","   'other',\n","   'than',\n","   'Britain',\n","   'until',\n","   'the',\n","   'scientific',\n","   'advice',\n","   'was',\n","   'clearer',\n","   '.']],\n"," 'pos_tags': [[22,\n","   27,\n","   21,\n","   35,\n","   12,\n","   22,\n","   22,\n","   27,\n","   16,\n","   21,\n","   22,\n","   22,\n","   38,\n","   15,\n","   22,\n","   24,\n","   20,\n","   37,\n","   21,\n","   15,\n","   24,\n","   16,\n","   15,\n","   22,\n","   15,\n","   12,\n","   16,\n","   21,\n","   38,\n","   17,\n","   7]],\n"," 'chunk_tags': [[11,\n","   11,\n","   12,\n","   13,\n","   11,\n","   12,\n","   12,\n","   11,\n","   12,\n","   12,\n","   12,\n","   12,\n","   21,\n","   13,\n","   11,\n","   12,\n","   21,\n","   22,\n","   11,\n","   13,\n","   11,\n","   1,\n","   13,\n","   11,\n","   17,\n","   11,\n","   12,\n","   12,\n","   21,\n","   1,\n","   0]],\n"," 'ner_tags': [[5,\n","   0,\n","   0,\n","   0,\n","   0,\n","   3,\n","   4,\n","   0,\n","   0,\n","   0,\n","   1,\n","   2,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   5,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0]]}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["coll_dataset['train'][4:5]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.628758Z","iopub.status.busy":"2024-03-04T14:25:48.628419Z","iopub.status.idle":"2024-03-04T14:25:48.639247Z","shell.execute_reply":"2024-03-04T14:25:48.638351Z","shell.execute_reply.started":"2024-03-04T14:25:48.628713Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["tokenize_and_align_labels(coll_dataset['train'][4:5])"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.640601Z","iopub.status.busy":"2024-03-04T14:25:48.640191Z","iopub.status.idle":"2024-03-04T14:25:48.649123Z","shell.execute_reply":"2024-03-04T14:25:48.648237Z","shell.execute_reply.started":"2024-03-04T14:25:48.640577Z"},"trusted":true},"outputs":[],"source":["# how the word is getting map with the tags\n","q = tokenize_and_align_labels(coll_dataset['train'][4:5])"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.650390Z","iopub.status.busy":"2024-03-04T14:25:48.650152Z","iopub.status.idle":"2024-03-04T14:25:48.660486Z","shell.execute_reply":"2024-03-04T14:25:48.659532Z","shell.execute_reply.started":"2024-03-04T14:25:48.650368Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS]___________________________________ -100\n","germany_________________________________ 5\n","'_______________________________________ 0\n","s_______________________________________ 0\n","representative__________________________ 0\n","to______________________________________ 0\n","the_____________________________________ 0\n","european________________________________ 3\n","union___________________________________ 4\n","'_______________________________________ 0\n","s_______________________________________ 0\n","veterinary______________________________ 0\n","committee_______________________________ 0\n","werner__________________________________ 1\n","z_______________________________________ 2\n","##wing__________________________________ 2\n","##mann__________________________________ 2\n","said____________________________________ 0\n","on______________________________________ 0\n","wednesday_______________________________ 0\n","consumers_______________________________ 0\n","should__________________________________ 0\n","buy_____________________________________ 0\n","sheep___________________________________ 0\n","##me____________________________________ 0\n","##at____________________________________ 0\n","from____________________________________ 0\n","countries_______________________________ 0\n","other___________________________________ 0\n","than____________________________________ 0\n","britain_________________________________ 5\n","until___________________________________ 0\n","the_____________________________________ 0\n","scientific______________________________ 0\n","advice__________________________________ 0\n","was_____________________________________ 0\n","clearer_________________________________ 0\n","._______________________________________ 0\n","[SEP]___________________________________ -100\n"]}],"source":["for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]), q['labels'][0]):\n","    print(f\"{token:_<40} {label}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:48.661956Z","iopub.status.busy":"2024-03-04T14:25:48.661607Z","iopub.status.idle":"2024-03-04T14:25:52.260587Z","shell.execute_reply":"2024-03-04T14:25:52.259776Z","shell.execute_reply.started":"2024-03-04T14:25:48.661932Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9af574afb79b45f08f87a318ec5d6853","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/15 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7cc3c6366aab41c28bbbbbe8c6a3692c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"171e3bf2d92d47f0b25ad32c0176b1bd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["## Applying on entire data\n","tokenized_datasets = coll_dataset.map(tokenize_and_align_labels, batched=True)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:52.262182Z","iopub.status.busy":"2024-03-04T14:25:52.261898Z","iopub.status.idle":"2024-03-04T14:25:52.268476Z","shell.execute_reply":"2024-03-04T14:25:52.267422Z","shell.execute_reply.started":"2024-03-04T14:25:52.262156Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 14042\n","})"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets['train']"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:52.274790Z","iopub.status.busy":"2024-03-04T14:25:52.274481Z","iopub.status.idle":"2024-03-04T14:25:52.308327Z","shell.execute_reply":"2024-03-04T14:25:52.307440Z","shell.execute_reply.started":"2024-03-04T14:25:52.274761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': '0',\n"," 'tokens': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.'],\n"," 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n"," 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n"," 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n"," 'input_ids': [101,\n","  7327,\n","  19164,\n","  2446,\n","  2655,\n","  2000,\n","  17757,\n","  2329,\n","  12559,\n","  1012,\n","  102],\n"," 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets['train'][0]"]},{"cell_type":"markdown","metadata":{},"source":["Now we can see, we are getting input_ids along with the labels"]},{"cell_type":"markdown","metadata":{},"source":["Load the model:\n","- https://huggingface.co/transformers/v3.0.2/model_doc/auto.html"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:52.309722Z","iopub.status.busy":"2024-03-04T14:25:52.309402Z","iopub.status.idle":"2024-03-04T14:25:56.318815Z","shell.execute_reply":"2024-03-04T14:25:56.318009Z","shell.execute_reply.started":"2024-03-04T14:25:52.309697Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3844bd057f9744ba986a80d68acbdf4b","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\",num_labels=9)"]},{"cell_type":"markdown","metadata":{},"source":["We are using pretrained model and finetune it"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.320507Z","iopub.status.busy":"2024-03-04T14:25:56.320147Z","iopub.status.idle":"2024-03-04T14:25:56.363387Z","shell.execute_reply":"2024-03-04T14:25:56.362670Z","shell.execute_reply.started":"2024-03-04T14:25:56.320474Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments, Trainer"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.364645Z","iopub.status.busy":"2024-03-04T14:25:56.364374Z","iopub.status.idle":"2024-03-04T14:25:56.422657Z","shell.execute_reply":"2024-03-04T14:25:56.421764Z","shell.execute_reply.started":"2024-03-04T14:25:56.364621Z"},"trusted":true},"outputs":[],"source":["args = TrainingArguments(\n","\"test-ner\",\n","evaluation_strategy = \"epoch\",\n","learning_rate=2e-5,\n","per_device_train_batch_size=16,\n","per_device_eval_batch_size=16,\n","num_train_epochs=7,\n","weight_decay=0.01\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.424150Z","iopub.status.busy":"2024-03-04T14:25:56.423873Z","iopub.status.idle":"2024-03-04T14:25:56.802605Z","shell.execute_reply":"2024-03-04T14:25:56.801770Z","shell.execute_reply.started":"2024-03-04T14:25:56.424125Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6ce9a39a65743dfb0de6f9f66ee4f1a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["metric = datasets.load_metric('seqeval')"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.803970Z","iopub.status.busy":"2024-03-04T14:25:56.803683Z","iopub.status.idle":"2024-03-04T14:25:56.811483Z","shell.execute_reply":"2024-03-04T14:25:56.810680Z","shell.execute_reply.started":"2024-03-04T14:25:56.803945Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': '405',\n"," 'tokens': ['Kenny',\n","  'Dalglish',\n","  'spoke',\n","  'on',\n","  'Thursday',\n","  'of',\n","  'his',\n","  'sadness',\n","  'at',\n","  'leaving',\n","  'Blackburn',\n","  ',',\n","  'the',\n","  'club',\n","  'he',\n","  'led',\n","  'to',\n","  'the',\n","  'English',\n","  'premier',\n","  'league',\n","  'title',\n","  'in',\n","  '1994-95',\n","  '.'],\n"," 'pos_tags': [22,\n","  22,\n","  38,\n","  15,\n","  22,\n","  15,\n","  29,\n","  21,\n","  15,\n","  39,\n","  22,\n","  6,\n","  12,\n","  21,\n","  28,\n","  38,\n","  35,\n","  12,\n","  16,\n","  16,\n","  21,\n","  21,\n","  15,\n","  11,\n","  7],\n"," 'chunk_tags': [11,\n","  12,\n","  21,\n","  13,\n","  11,\n","  13,\n","  11,\n","  12,\n","  13,\n","  21,\n","  11,\n","  0,\n","  11,\n","  12,\n","  11,\n","  21,\n","  13,\n","  11,\n","  12,\n","  12,\n","  12,\n","  12,\n","  13,\n","  11,\n","  0],\n"," 'ner_tags': [1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  3,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  7,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["example_text"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.812968Z","iopub.status.busy":"2024-03-04T14:25:56.812628Z","iopub.status.idle":"2024-03-04T14:25:56.823720Z","shell.execute_reply":"2024-03-04T14:25:56.822780Z","shell.execute_reply.started":"2024-03-04T14:25:56.812944Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["label_list = coll_dataset['train'].features['ner_tags'].feature.names\n","\n","label_list"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.825285Z","iopub.status.busy":"2024-03-04T14:25:56.824814Z","iopub.status.idle":"2024-03-04T14:25:56.834809Z","shell.execute_reply":"2024-03-04T14:25:56.834037Z","shell.execute_reply.started":"2024-03-04T14:25:56.825261Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","2\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","3\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","7\n","0\n","0\n","0\n","0\n","0\n","0\n"]}],"source":["for i in example_text['ner_tags']:\n","    print(i)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.836317Z","iopub.status.busy":"2024-03-04T14:25:56.835931Z","iopub.status.idle":"2024-03-04T14:25:56.846295Z","shell.execute_reply":"2024-03-04T14:25:56.845419Z","shell.execute_reply.started":"2024-03-04T14:25:56.836287Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['B-PER',\n"," 'I-PER',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'B-ORG',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'B-MISC',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O']"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# keeping it all inside a list\n","labels = [label_list[i] for i in example_text['ner_tags']]\n","labels"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.847646Z","iopub.status.busy":"2024-03-04T14:25:56.847392Z","iopub.status.idle":"2024-03-04T14:25:56.865353Z","shell.execute_reply":"2024-03-04T14:25:56.864532Z","shell.execute_reply.started":"2024-03-04T14:25:56.847624Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n"," 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n"," 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n"," 'overall_precision': 1.0,\n"," 'overall_recall': 1.0,\n"," 'overall_f1': 1.0,\n"," 'overall_accuracy': 1.0}"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["metric.compute(predictions=[labels], references=[labels])\n","\n","# as of now both the labels are same, target and prediction, so acc = 100%"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.866964Z","iopub.status.busy":"2024-03-04T14:25:56.866566Z","iopub.status.idle":"2024-03-04T14:25:56.874419Z","shell.execute_reply":"2024-03-04T14:25:56.873550Z","shell.execute_reply.started":"2024-03-04T14:25:56.866939Z"},"trusted":true},"outputs":[],"source":["# define method to compute the scores\n","\n","def compute_metrics(eval_preds):\n","    pred_logits, labels = eval_preds\n","\n","    pred_logits = np.argmax(pred_logits, axis=2)\n","    # the logits and the probabilities are in the same order,\n","    # so we don’t need to apply the softmax\n","\n","    # We remove all the values where the label is -100\n","    predictions = [\n","        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(pred_logits, labels)\n","    ]\n","\n","    true_labels = [\n","      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n","       for prediction, label in zip(pred_logits, labels)\n","   ]\n","    results = metric.compute(predictions=predictions, references=true_labels)\n","\n","    return {\n","          \"precision\": results[\"overall_precision\"],\n","          \"recall\": results[\"overall_recall\"],\n","          \"f1\": results[\"overall_f1\"],\n","          \"accuracy\": results[\"overall_accuracy\"],\n","  }"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.875883Z","iopub.status.busy":"2024-03-04T14:25:56.875493Z","iopub.status.idle":"2024-03-04T14:25:56.889031Z","shell.execute_reply":"2024-03-04T14:25:56.888229Z","shell.execute_reply.started":"2024-03-04T14:25:56.875808Z"},"trusted":true},"outputs":[],"source":["# define data collator\n","\n","data_collator=DataCollatorForTokenClassification(tokenizer)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:56.890808Z","iopub.status.busy":"2024-03-04T14:25:56.890192Z","iopub.status.idle":"2024-03-04T14:25:58.480700Z","shell.execute_reply":"2024-03-04T14:25:58.479962Z","shell.execute_reply.started":"2024-03-04T14:25:56.890775Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","   model,\n","   args,\n","   train_dataset=tokenized_datasets[\"train\"],\n","   eval_dataset=tokenized_datasets[\"validation\"],\n","   data_collator=data_collator,\n","   tokenizer=tokenizer,\n","   compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:25:58.481997Z","iopub.status.busy":"2024-03-04T14:25:58.481699Z","iopub.status.idle":"2024-03-04T14:41:46.617257Z","shell.execute_reply":"2024-03-04T14:41:46.616245Z","shell.execute_reply.started":"2024-03-04T14:25:58.481971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240304_142618-9lzfxwfu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/work-on-improvement/huggingface/runs/9lzfxwfu' target=\"_blank\">warm-surf-12</a></strong> to <a href='https://wandb.ai/work-on-improvement/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/work-on-improvement/huggingface' target=\"_blank\">https://wandb.ai/work-on-improvement/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/work-on-improvement/huggingface/runs/9lzfxwfu' target=\"_blank\">https://wandb.ai/work-on-improvement/huggingface/runs/9lzfxwfu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3073' max='3073' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3073/3073 14:53, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.067201</td>\n","      <td>0.905509</td>\n","      <td>0.923034</td>\n","      <td>0.914188</td>\n","      <td>0.981461</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.188300</td>\n","      <td>0.056479</td>\n","      <td>0.920544</td>\n","      <td>0.938360</td>\n","      <td>0.929367</td>\n","      <td>0.983446</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.048700</td>\n","      <td>0.057639</td>\n","      <td>0.934452</td>\n","      <td>0.947310</td>\n","      <td>0.940837</td>\n","      <td>0.986052</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.026600</td>\n","      <td>0.059109</td>\n","      <td>0.937500</td>\n","      <td>0.946415</td>\n","      <td>0.941936</td>\n","      <td>0.986163</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.016700</td>\n","      <td>0.064486</td>\n","      <td>0.932863</td>\n","      <td>0.946638</td>\n","      <td>0.939700</td>\n","      <td>0.985734</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.012800</td>\n","      <td>0.063506</td>\n","      <td>0.940955</td>\n","      <td>0.952008</td>\n","      <td>0.946449</td>\n","      <td>0.987021</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.008500</td>\n","      <td>0.065214</td>\n","      <td>0.938514</td>\n","      <td>0.951113</td>\n","      <td>0.944772</td>\n","      <td>0.986783</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=3073, training_loss=0.04927719170830749, metrics={'train_runtime': 947.8195, 'train_samples_per_second': 103.705, 'train_steps_per_second': 3.242, 'total_flos': 2642738912648208.0, 'train_loss': 0.04927719170830749, 'epoch': 7.0})"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# run the model for finetuning, we can explore by varying #of epochs\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["To save the model:\n","- while saving the model, a config and safetensor file is created\n","- the config file contains 'id2label' and 'label2id' dict\n","- "]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:46.618964Z","iopub.status.busy":"2024-03-04T14:41:46.618584Z","iopub.status.idle":"2024-03-04T14:41:47.407727Z","shell.execute_reply":"2024-03-04T14:41:47.406532Z","shell.execute_reply.started":"2024-03-04T14:41:46.618929Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained('ner_model')\n","print(\"Model Saved...\")"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.409401Z","iopub.status.busy":"2024-03-04T14:41:47.409097Z","iopub.status.idle":"2024-03-04T14:41:47.436289Z","shell.execute_reply":"2024-03-04T14:41:47.435241Z","shell.execute_reply.started":"2024-03-04T14:41:47.409374Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('tokenizer/tokenizer_config.json',\n"," 'tokenizer/special_tokens_map.json',\n"," 'tokenizer/vocab.txt',\n"," 'tokenizer/added_tokens.json',\n"," 'tokenizer/tokenizer.json')"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# save tokenizer \n","tokenizer.save_pretrained('tokenizer')"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.438302Z","iopub.status.busy":"2024-03-04T14:41:47.437486Z","iopub.status.idle":"2024-03-04T14:41:47.444806Z","shell.execute_reply":"2024-03-04T14:41:47.443706Z","shell.execute_reply.started":"2024-03-04T14:41:47.438276Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["label_list"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.446080Z","iopub.status.busy":"2024-03-04T14:41:47.445809Z","iopub.status.idle":"2024-03-04T14:41:47.457857Z","shell.execute_reply":"2024-03-04T14:41:47.456746Z","shell.execute_reply.started":"2024-03-04T14:41:47.446057Z"},"trusted":true},"outputs":[],"source":["id2label = {\n","    str(i): label for i,label in enumerate(label_list)\n","}"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.459407Z","iopub.status.busy":"2024-03-04T14:41:47.459094Z","iopub.status.idle":"2024-03-04T14:41:47.472862Z","shell.execute_reply":"2024-03-04T14:41:47.472093Z","shell.execute_reply.started":"2024-03-04T14:41:47.459374Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'0': 'O',\n"," '1': 'B-PER',\n"," '2': 'I-PER',\n"," '3': 'B-ORG',\n"," '4': 'I-ORG',\n"," '5': 'B-LOC',\n"," '6': 'I-LOC',\n"," '7': 'B-MISC',\n"," '8': 'I-MISC'}"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["id2label"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.474182Z","iopub.status.busy":"2024-03-04T14:41:47.473934Z","iopub.status.idle":"2024-03-04T14:41:47.483791Z","shell.execute_reply":"2024-03-04T14:41:47.482893Z","shell.execute_reply.started":"2024-03-04T14:41:47.474162Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'O': '0',\n"," 'B-PER': '1',\n"," 'I-PER': '2',\n"," 'B-ORG': '3',\n"," 'I-ORG': '4',\n"," 'B-LOC': '5',\n"," 'I-LOC': '6',\n"," 'B-MISC': '7',\n"," 'I-MISC': '8'}"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["label2id = {\n","    label: str(i) for i,label in enumerate(label_list)\n","}\n","\n","label2id"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:41:47.485225Z","iopub.status.busy":"2024-03-04T14:41:47.484954Z","iopub.status.idle":"2024-03-04T14:41:47.492786Z","shell.execute_reply":"2024-03-04T14:41:47.491825Z","shell.execute_reply.started":"2024-03-04T14:41:47.485191Z"},"trusted":true},"outputs":[],"source":["import json"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:42:19.428144Z","iopub.status.busy":"2024-03-04T14:42:19.427419Z","iopub.status.idle":"2024-03-04T14:42:19.434052Z","shell.execute_reply":"2024-03-04T14:42:19.432882Z","shell.execute_reply.started":"2024-03-04T14:42:19.428110Z"},"trusted":true},"outputs":[],"source":["config=json.load(open(\"/kaggle/working/ner_model/config.json\"))"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:43:49.011694Z","iopub.status.busy":"2024-03-04T14:43:49.011287Z","iopub.status.idle":"2024-03-04T14:43:49.021425Z","shell.execute_reply":"2024-03-04T14:43:49.020327Z","shell.execute_reply.started":"2024-03-04T14:43:49.011662Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'_name_or_path': 'bert-base-uncased',\n"," 'architectures': ['BertForTokenClassification'],\n"," 'attention_probs_dropout_prob': 0.1,\n"," 'classifier_dropout': None,\n"," 'gradient_checkpointing': False,\n"," 'hidden_act': 'gelu',\n"," 'hidden_dropout_prob': 0.1,\n"," 'hidden_size': 768,\n"," 'id2label': {'0': 'LABEL_0',\n","  '1': 'LABEL_1',\n","  '2': 'LABEL_2',\n","  '3': 'LABEL_3',\n","  '4': 'LABEL_4',\n","  '5': 'LABEL_5',\n","  '6': 'LABEL_6',\n","  '7': 'LABEL_7',\n","  '8': 'LABEL_8'},\n"," 'initializer_range': 0.02,\n"," 'intermediate_size': 3072,\n"," 'label2id': {'LABEL_0': 0,\n","  'LABEL_1': 1,\n","  'LABEL_2': 2,\n","  'LABEL_3': 3,\n","  'LABEL_4': 4,\n","  'LABEL_5': 5,\n","  'LABEL_6': 6,\n","  'LABEL_7': 7,\n","  'LABEL_8': 8},\n"," 'layer_norm_eps': 1e-12,\n"," 'max_position_embeddings': 512,\n"," 'model_type': 'bert',\n"," 'num_attention_heads': 12,\n"," 'num_hidden_layers': 12,\n"," 'pad_token_id': 0,\n"," 'position_embedding_type': 'absolute',\n"," 'torch_dtype': 'float32',\n"," 'transformers_version': '4.38.1',\n"," 'type_vocab_size': 2,\n"," 'use_cache': True,\n"," 'vocab_size': 30522}"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["config\n"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:44:49.310396Z","iopub.status.busy":"2024-03-04T14:44:49.309670Z","iopub.status.idle":"2024-03-04T14:44:49.316581Z","shell.execute_reply":"2024-03-04T14:44:49.314838Z","shell.execute_reply.started":"2024-03-04T14:44:49.310356Z"},"trusted":true},"outputs":[],"source":["config[\"id2label\"] = id2label"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:45:44.049154Z","iopub.status.busy":"2024-03-04T14:45:44.048550Z","iopub.status.idle":"2024-03-04T14:45:44.054452Z","shell.execute_reply":"2024-03-04T14:45:44.053329Z","shell.execute_reply.started":"2024-03-04T14:45:44.049120Z"},"trusted":true},"outputs":[],"source":["config[\"label2id\"] = label2id"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:06.578575Z","iopub.status.busy":"2024-03-04T14:46:06.577996Z","iopub.status.idle":"2024-03-04T14:46:06.584650Z","shell.execute_reply":"2024-03-04T14:46:06.583458Z","shell.execute_reply.started":"2024-03-04T14:46:06.578543Z"},"trusted":true},"outputs":[],"source":["json.dump(config,open(\"/kaggle/working/ner_model/config.json\",\"w\"))\n"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:37.774983Z","iopub.status.busy":"2024-03-04T14:46:37.774367Z","iopub.status.idle":"2024-03-04T14:46:38.027050Z","shell.execute_reply":"2024-03-04T14:46:38.025899Z","shell.execute_reply.started":"2024-03-04T14:46:37.774947Z"},"trusted":true},"outputs":[],"source":["model_fine_tuned=AutoModelForTokenClassification.from_pretrained(\"ner_model\")"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:39.985549Z","iopub.status.busy":"2024-03-04T14:46:39.984797Z","iopub.status.idle":"2024-03-04T14:46:39.997655Z","shell.execute_reply":"2024-03-04T14:46:39.996661Z","shell.execute_reply.started":"2024-03-04T14:46:39.985515Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["model_fine_tuned"]},{"cell_type":"markdown","metadata":{},"source":["Inferencing to check out the predictions"]},{"cell_type":"markdown","metadata":{},"source":["Transformer Pipeline"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:47.175059Z","iopub.status.busy":"2024-03-04T14:46:47.174677Z","iopub.status.idle":"2024-03-04T14:46:49.209133Z","shell.execute_reply":"2024-03-04T14:46:49.208005Z","shell.execute_reply.started":"2024-03-04T14:46:47.175029Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:49.211553Z","iopub.status.busy":"2024-03-04T14:46:49.211243Z","iopub.status.idle":"2024-03-04T14:46:49.223313Z","shell.execute_reply":"2024-03-04T14:46:49.222319Z","shell.execute_reply.started":"2024-03-04T14:46:49.211525Z"},"trusted":true},"outputs":[],"source":["# load the finetuned model and tokenizer, along with project-name:'ner'\n","nlp_pipeline=pipeline(\"ner\",model=model_fine_tuned,tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:49.225154Z","iopub.status.busy":"2024-03-04T14:46:49.224786Z","iopub.status.idle":"2024-03-04T14:46:49.233215Z","shell.execute_reply":"2024-03-04T14:46:49.232101Z","shell.execute_reply.started":"2024-03-04T14:46:49.225119Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<transformers.pipelines.token_classification.TokenClassificationPipeline at 0x7b958550c8b0>"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["nlp_pipeline"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:47:46.504273Z","iopub.status.busy":"2024-03-04T14:47:46.503568Z","iopub.status.idle":"2024-03-04T14:47:46.509798Z","shell.execute_reply":"2024-03-04T14:47:46.508722Z","shell.execute_reply.started":"2024-03-04T14:47:46.504239Z"},"trusted":true},"outputs":[],"source":["example=\"Narendra Modi is Indian Politician\""]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:56.119537Z","iopub.status.busy":"2024-03-04T14:46:56.118903Z","iopub.status.idle":"2024-03-04T14:46:56.124984Z","shell.execute_reply":"2024-03-04T14:46:56.123792Z","shell.execute_reply.started":"2024-03-04T14:46:56.119507Z"},"trusted":true},"outputs":[],"source":["example=\"apple launch mobile while eating apple which taste like orange\""]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T14:46:57.345199Z","iopub.status.busy":"2024-03-04T14:46:57.344437Z","iopub.status.idle":"2024-03-04T14:46:57.428179Z","shell.execute_reply":"2024-03-04T14:46:57.426825Z","shell.execute_reply.started":"2024-03-04T14:46:57.345165Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'entity': 'B-ORG',\n","  'score': 0.9943808,\n","  'index': 1,\n","  'word': 'apple',\n","  'start': 0,\n","  'end': 5},\n"," {'entity': 'B-MISC',\n","  'score': 0.9416092,\n","  'index': 6,\n","  'word': 'apple',\n","  'start': 33,\n","  'end': 38},\n"," {'entity': 'B-MISC',\n","  'score': 0.8638995,\n","  'index': 10,\n","  'word': 'orange',\n","  'start': 56,\n","  'end': 62}]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["nlp_pipeline(example)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
